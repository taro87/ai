{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "942c6923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.container{width:90% !important;}\n",
       "div.cell.code_cell.rendered{width:100%;}\n",
       "div.input_prompt{padding:0px;}\n",
       "div.CodeMirror {font-family:Consolas; font-size:16pt;}\n",
       "div.text_cell_render.rendered_html{font-size:16pt;}\n",
       "div.output {font-size:12pt; \n",
       "las; font-size:16pt;}\n",
       "div.prompt {min-width:70px;}\n",
       "div#toc-wrapper{padding-top:120px;}\n",
       "div.text_cell_render ul li{font-size:16pt;padding:5px;}\n",
       "table.dataframe{font-size:16px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "div.container{width:90% !important;}\n",
    "div.cell.code_cell.rendered{width:100%;}\n",
    "div.input_prompt{padding:0px;}\n",
    "div.CodeMirror {font-family:Consolas; font-size:16pt;}\n",
    "div.text_cell_render.rendered_html{font-size:16pt;}\n",
    "div.output {font-size:12pt; \n",
    "las; font-size:16pt;}\n",
    "div.prompt {min-width:70px;}\n",
    "div#toc-wrapper{padding-top:120px;}\n",
    "div.text_cell_render ul li{font-size:16pt;padding:5px;}\n",
    "table.dataframe{font-size:16px;}\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad20d5e9",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">ch1. 허깅페이스</span>\n",
    "- Inference API 이용 : 모델의 결과를 surver에서\n",
    "- pipeline() 이용 : 모델을 다운로드받아 모델의 결과를 local에서\n",
    "    * raw text -> tokenizer -> model -> [0.11, 0.55, 0.XX,~] logits값으로 prediction결과 출력\n",
    "```\n",
    "허깅페이스 transformers에서 지원하는 task\n",
    "\"sentiment-analysis\" : \"text-classification\"의 별칭(감정분석 전용으로 사용)\n",
    "\"text-classification\" : 감정분석, 뉴스분류, 리뷰 분류 등 일반적인 문장 분류\n",
    "\"zero-shot-classification\" : 레이블을 학습 없이 주어진 후보군 중에서 분류\n",
    "\"token-calssification\" : 개체명 인식(NER : Named Entity Recognition) 등 단위 라벨링\n",
    "\"ner\" : \"token-calssification\"의 별칭\n",
    "\"fill-mask\" : 빈칸 채우기\n",
    "\"text-generation\" : 텍스트 생성 (GPT류 모델에 사용)\n",
    "\"text2text-generation\" : 번역, 요약 등 입력 -> 출력 변환\n",
    "\"translation\" : 번역\n",
    "\"summarization\" : 텍스트요약\n",
    "\"question-answering\" : 주어진 context를 보고 질문에 답하기\n",
    "\"image-to-text\" : 그림을 설명\n",
    "\"image-classification\" : 이미지분류\n",
    "```\n",
    "\n",
    "## 1. 텍스트 기반 감정분석(긍정/부정)\n",
    "- C:\\Users\\Admin\\.cache\\huggingface/hub 모델 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d66c19f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import logging\n",
    "# 경고 제거\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# transformers 로깅 레벨 조정\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "# Hugging Face symlink 경고 제거\n",
    "os.environ['HF_HUB_DISABLE_SYMLINKS_WARNING'] = '1'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# from transformers import pipeline, logging as hf_logging\n",
    "# hf_logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48f4ac98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e39d3a6079064d1aadcbce11a966ca56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a445937e46a4b1dac930e173a5e72af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab1e20ab9fd40d280de637ad31edd73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "260bc70b8a33477caa37045a14845b77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598049521446228}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(task=\"sentiment-analysis\")\n",
    "classifier(\"I've been waiting for a HuggingFace course my whole life.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0375f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(task=\"sentiment-analysis\",\n",
    "                     model=\"matthewburke/korean_sentiment\")\n",
    "texts = ['미워하지만 사랑해', '그립지만 용서못해', '못생겼어', '잘생겼어']\n",
    "result = classifier(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b66d8918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "미워하지만 사랑해 => 긍정 : 0.9526359438896179\n",
      "그립지만 용서못해 => 부정 : 0.7990366816520691\n",
      "못생겼어 => 부정 : 0.9636958241462708\n",
      "잘생겼어 => 긍정 : 0.9676699638366699\n"
     ]
    }
   ],
   "source": [
    "for text , result in zip(texts, classifier(texts)):\n",
    "    label = '긍정' if result['label']=='LABEL_1' else '부정'\n",
    "    print(f\"{text} => {label} : {result['score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b84766e",
   "metadata": {},
   "source": [
    "## 2. 제로샷분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa27bc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74f3f5bcf0f44d7dbc8bed5c46486c10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "835ce4daae4f479b844522f03809192c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d50d5d9edfb4e108f7a7ea0f1a3a26f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4364b6f3e9e84bb8b2fa44cf7783b90e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3301613499a43cf895cf138e0faaae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b974450cb3dd4354839fbc62a8264e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'This is a course about the Transformers library',\n",
       " 'labels': ['education', 'business', 'politics'],\n",
       " 'scores': [0.8445960283279419, 0.11197635531425476, 0.04342760890722275]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "classifier(\n",
    "    \"This is a course about the Transformers library\",\n",
    "    candidate_labels=[\"education\", \"politics\", \"business\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c90dd6",
   "metadata": {},
   "source": [
    "## 3.text 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ecafc39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de7febcc233941c79e5ba135fd3733e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ac65bd6a27466d96561bb0685616b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c29a3c02ccd342f5bb242f855c022135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "148c9796fc25456cb19f1099b3486356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d16d3185549243e3a65bcd8154807354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c949c7373a70482cb0268f441bc4df8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54339b08a5fa4737af5f984eb1ad5940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you how to write a Python program that will make use of the power of the power of Python and the power of the powerful Python programming language. All you need is a Python interpreter, a Windows computer or a Python interpreter written in C++.\\n\\nYou will learn Python in Python 3, 2, 3, 4, 5, 6 and 7.\\n\\nTo get started, you need to start by reading the introduction to the language.\\n\\nYou will also need a Python installation, which you can install from an external location.\\n\\nWe will discuss using this as an introduction to the language, and where to find it.\\n\\nPython 3.x\\n\\nIn this course, we will be using Python 3.x to write some code. We will use it to help us write code for other projects. First of all, we will use C++ to write some Python programs.\\n\\nWe will use the functions that C++ provides to create and access variables. Next, we will use the built-in constants to make the value of a variable. Finally, we will use the built-in functions to write code.\\n\\nThese are the main sections of the course.\\n\\nYou will need to read the documentation to understand how C++ works.\\n\\n'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\", \"gpt2\") # 택스트 생성 gpt3부터는 허깅페이스 없음\n",
    "generator(\"In this course, we will teach you how to\",\n",
    "         pad_token_id=generator.tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "627dc0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "무녀 히나와 용사 키라는 마왕을 무찌르기 위해 여행하는 것이 꿈이라며 다른 세 개의 왕, 용사를 거느리고 마왕으로부터 마왕에 의해 암살당할 위기에 처한 세 여신을 대신해 그녀를 구출한다.\n",
      "마왕 역시 그녀에게 의지하고 있는 만큼 그녀의 정체는 바로 히나를 죽인 범인일 가능성이 크다.\n",
      "그들은 세 명의 왕 중 가장 먼저 탈출하여 그의 계획을 실행하고, 자신의 임무를 성공적으로 완수하기 위해 그녀를 세 명에 나누어 살해한다.\n",
      "이윽고 그는 새로운 길을 떠난다.\n",
      "세 왕과는 달리 히나는 한 번의 여행에 불과했다.\n",
      "또한 히나가 가장 오랫동안\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\", \"skt/kogpt2-base-v2\") # 택스트 생성 gpt3부터는 허깅페이스 없음\n",
    "result = generator('무녀 히나와 용사 키라는 마왕을 무찌르기 위해 여행',\n",
    "         pad_token_id=generator.tokenizer.eos_token_id,\n",
    "         max_new_tokens = 100, # 생성할 최대 길이(생성할 토큰 수)\n",
    "         num_return_sequences=1, # 생성할 문장 갯수\n",
    "         do_sample=True, # 다양한 샘플 사용\n",
    "         top_k=50, # top_k 샘플링(확률 높은 상위 50개 토큰만 사용)\n",
    "         top_p=0.95, # 확률이 높은 순서대로 95%가 될 때까지의 단어들로만 후보로 사용\n",
    "         temperature=1.2, # 창의성 조절(낮을수록 보수적)\n",
    "         no_repeat_ngram_size=2) # 반복방지\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18418e1b",
   "metadata": {},
   "source": [
    "## 4. 마스크(빈칸) 채우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4097041",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google-bert/bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.8635818958282471,\n",
       "  'token': 1010,\n",
       "  'token_str': ',',\n",
       "  'sequence': 'hello, my dalring'},\n",
       " {'score': 0.07325759530067444,\n",
       "  'token': 2000,\n",
       "  'token_str': 'to',\n",
       "  'sequence': 'hello to my dalring'}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker = pipeline(\"fill-mask\",\n",
    "                   model=\"google-bert/bert-base-uncased\")\n",
    "unmasker(\"Hello [MASK] my dalring\", top_k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdee7b4",
   "metadata": {},
   "source": [
    "### ※ inferenceAPI 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "deb28915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "# os.environ['HF_TOKEN']\n",
    "# 허깅페이스 토근을 READ권한으로 생성하여 .env에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "881d3c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FillMaskOutputElement(score=0.8635819554328918, sequence='hello, my dalring', token=1010, token_str=',', fill_mask_output_token_str=None), FillMaskOutputElement(score=0.07325738668441772, sequence='hello to my dalring', token=2000, token_str='to', fill_mask_output_token_str=None)]\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "client = InferenceClient(\n",
    "            provider=\"hf-inference\",\n",
    "            api_key=os.environ['HF_TOKEN'] #허깅페이스 토큰 키\n",
    "            \n",
    ")\n",
    "result = client.fill_mask(\n",
    "        \"Hello [MASK] my dalring\",\n",
    "        model=\"google-bert/bert-base-uncased\",\n",
    "        top_k=2 # 기본 5개\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6fcc9ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello, my dalring (86.36%)', 'hello to my dalring (7.33%)']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f'{r.sequence} ({r.score:.2%})' for r in result]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab9d9a3",
   "metadata": {},
   "source": [
    "## 5. 개채명 인식(NER : Named Entity Recognition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "35ddc31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0b1045d39dd42178d85b849fa598548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/998 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09e5dd6b138c4df18f871a888cb11196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abf89f68ae47496ab170f63046f22012",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb06c2dad9441b3ae44c126c0978f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'ORG',\n",
       "  'score': 0.7420061,\n",
       "  'word': 'Hugging face',\n",
       "  'start': 30,\n",
       "  'end': 42},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9996061,\n",
       "  'word': 'Korea',\n",
       "  'start': 46,\n",
       "  'end': 51}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner = pipeline(task=\"ner\",\n",
    "              model=\"dbmdz/bert-large-cased-finetuned-conll03-english\",\n",
    "              grouped_entities=True) # 개체들은 그릅으로 묶을지 말지 여부\n",
    "ner(\"My name is taro and i work at Hugging face in Korea\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e636e87e",
   "metadata": {},
   "source": [
    "## 6. 질의 응답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "97bff628",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.661173720494844,\n",
       " 'start': 30,\n",
       " 'end': 53,\n",
       " 'answer': 'hugging face in bangkok'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answer = pipeline(\"question-answering\",\n",
    "                          \"distilbert/distilbert-base-cased-distilled-squad\")\n",
    "question_answer(\n",
    "        question=\"Where do I work?\",\n",
    "        context= \"My name is Taro and I work at hugging face in bangkok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "369e46ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"My name is Taro and I work at hugging face in bangkok\"\n",
    "result = question_answer(question=\"Where do I work?\", context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dbcfb42e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('hugging face in bangkok', 'hugging face in bangkok', 0.661173720494844)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.get('answer'), context[result.get('start') : result.get('end')], result.get('score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2a6295",
   "metadata": {},
   "source": [
    "## 7. 문서요약\n",
    "- 현재 torch 버전이 2.6이하면 허깅페이스에서 강제로 막고 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "92668827",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Your max_length is set to 130, but your input_length is only 79. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=39)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' Your max_length is set to 130, but your input_length has only 73 . Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max length manually .'}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer = pipeline(task=\"summarization\",\n",
    "                     model=\"sshleifer/distilbart-cnn-12-6\")\n",
    "summarizer(\n",
    "    \"\"\"\n",
    "Device set to use cpu\n",
    "Your max_length is set to 130, but your input_length is only 73. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=36)    \n",
    "    \"\"\",\n",
    "    max_length=130, # 요약할 내용의 최대 토큰 수\n",
    "    min_length=30, # 요약할 내용의 최소 토큰 수\n",
    "    do_sample=False # 랜덤성이 없음/ 항상 비슷한 요약\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fddd10",
   "metadata": {},
   "source": [
    "## 8. 번역\n",
    "- pip install sacremoses : 한영번역에서의 경고를 줄이고, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "60efad37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'translation_text': '일반'}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator = pipeline(task=\"translation\",\n",
    "                     model=\"Helsinki-NLP/opus-mt-tc-big-en-ko\")\n",
    "translator(\n",
    "\"\"\"\n",
    "you\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5238f081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b85f81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce5a3e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfced59b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06265203",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-dl-nlp(ipykernel)",
   "language": "python",
   "name": "ml-dl-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
